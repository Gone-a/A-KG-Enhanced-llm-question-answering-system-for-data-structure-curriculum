import os
import json
import time
import re
import requests
from dotenv import load_dotenv
import sys
from volcenginesdkarkruntime import Ark
import concurrent.futures
from threading import Lock
import hashlib

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class KGAttributeGenerator:
    """æ•°æ®ç»“æ„çŸ¥è¯†å›¾è°±å±æ€§ç”Ÿæˆå™¨ï¼ˆè°ƒç”¨ç«å±±å¼•æ“å¤§æ¨¡å‹APIï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç«å±±å¼•æ“APIé…ç½®"""
        self.api_key = os.getenv("ARK_API_KEY")
        if not self.api_key:
            raise EnvironmentError(
                "è¯·è®¾ç½®ç«å±±å¼•æ“APIå¯†é’¥\n"
               
            )
        # å»é™¤APIå¯†é’¥ä¸­çš„ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰
        self.api_key = self.api_key.strip()
        
        # åˆå§‹åŒ–ç«å±±æ–¹èˆŸå®¢æˆ·ç«¯
        self.client = Ark(api_key=self.api_key)
        self.model_id = "doubao-seed-1-6-thinking-250715"
        
        # APIè°ƒç”¨ä¼˜åŒ–å‚æ•°
        self.api_timeout = 120  # å¢åŠ è¯·æ±‚è¶…æ—¶æ—¶é—´åˆ°120ç§’
        self.retry_attempts = 2  # å¢åŠ é‡è¯•æ¬¡æ•°åˆ°2æ¬¡
        self.retry_delay = 2  # å¢åŠ é‡è¯•å»¶è¿Ÿåˆ°2ç§’
        
        # å¹¶å‘æ§åˆ¶å’Œç¼“å­˜
        self.max_workers = 3  # å‡å°‘å¹¶å‘æ•°ä»¥é™ä½APIå‹åŠ›
        self.cache = {}  # å“åº”ç¼“å­˜
        self.cache_lock = Lock()  # ç¼“å­˜é”
        self.cache_file = "cache/api_cache.json"  # ç¼“å­˜æ–‡ä»¶
        # åˆå§‹åŒ–ç¼“å­˜å¤§å°è®°å½•
        self._last_cache_size = 0
        # åŠ è½½ç°æœ‰ç¼“å­˜
        self.load_cache()
        
        # ä»æä¾›çš„æ–‡ä»¶å†…å®¹ä¸­è§£æå®ä½“åˆ—è¡¨
        self.entities = self.parse_entities_file()
        
        # ä¼˜åŒ–åçš„å±æ€§è®¾è®¡ï¼ˆåŸºäºè®¡ç®—æœºç§‘å­¦æ ‡å‡†ï¼‰
        self.optimized_attrs = {
            "DataStructure": [
                "description", "storage_method", "properties", "time_complexity", 
                "space_complexity", "related_algorithms", "common_operations"
            ],
            "Algorithm": [
                "description", "principle", "applicable_conditions", "time_complexity",
                "space_complexity", "related_data_structures", "key_steps"
            ],
            "Operation": [
                "description", "complexity", "applied_to", "operation_type", 
                "side_effects", "typical_usage"
            ],
            "Complexity": [
                "notation", "description", "typical_cases", "explanation", 
                "best_case", "average_case", "worst_case", "example"
            ],
            "ApplicationScenario": [
                "description", "key_problem", "common_solutions", "related_data_structures",
                "related_algorithms", "real_world_examples"
            ],
            "PrincipleOrProperty": [
                "description", "key_characteristic", "implications", "related_concepts",
                "examples", "theoretical_basis"
            ]
        }
        
        # ä¿å­˜ç»“æœçš„JSONæ–‡ä»¶
        self.output_file = "data_structure_kg_optimized.json"
        self.start_time = time.time()
        
        # éªŒè¯å®ä½“åˆ—è¡¨
        if not self.entities:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å®ä½“ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼")
        print(f"âœ… è¯†åˆ«åˆ° {len(self.entities)} ä¸ªå®ä½“ï¼Œå¼€å§‹ç”Ÿæˆå±æ€§...")

    def parse_entities_file(self):
        """è§£ææä¾›çš„å®ä½“æ–‡ä»¶å†…å®¹"""
        # ä»ç”¨æˆ·æä¾›çš„æ–‡ä»¶å†…å®¹ä¸­æå–å®ä½“
        entities_str = """
æ ˆ,DataStructure
é˜Ÿåˆ—,DataStructure
é“¾è¡¨,DataStructure
äºŒå‰æ ‘,DataStructure
å›¾,DataStructure
å“ˆå¸Œè¡¨,DataStructure
æ•°ç»„,DataStructure
æ ‘,DataStructure
äºŒå‰æœç´¢æ ‘,DataStructure
å¹³è¡¡äºŒå‰æ ‘,DataStructure
å †,DataStructure
å¤§æ ¹å †,DataStructure
å°æ ¹å †,DataStructure
å•é“¾è¡¨,DataStructure
åŒå‘é“¾è¡¨,DataStructure
å¾ªç¯é“¾è¡¨,DataStructure
çº¿æ€§è¡¨,DataStructure
ä¼˜å…ˆé˜Ÿåˆ—,DataStructure
B+æ ‘,DataStructure
Bæ ‘,DataStructure
çº¢é»‘æ ‘,DataStructure
çº¿æ®µæ ‘,DataStructure
æ ‘çŠ¶æ•°ç»„,DataStructure
å­—å…¸æ ‘,DataStructure
åç¼€æ ‘,DataStructure
å‰ç¼€æ ‘,DataStructure
ACè‡ªåŠ¨æœº,DataStructure
è·³è·ƒè¡¨,DataStructure
å¸ƒéš†è¿‡æ»¤å™¨,DataStructure
å¹¶æŸ¥é›†,DataStructure
äºŒé¡¹å †,DataStructure
æ–æ³¢é‚£å¥‘å †,DataStructure
åŒç«¯é˜Ÿåˆ—,DataStructure
å¾ªç¯é˜Ÿåˆ—,DataStructure
äºŒå‰å †,DataStructure
å¯æŒä¹…åŒ–æ•°æ®ç»“æ„,DataStructure
ç”Ÿæˆæ£®æ—,DataStructure
LRUç¼“å­˜,DataStructure
LFUç¼“å­˜,DataStructure
ä¸ç›¸äº¤é›†åˆ,DataStructure
å…¥æ ˆ,Operation
å‡ºæ ˆ,Operation
å…¥é˜Ÿ,Operation
å‡ºé˜Ÿ,Operation
æ’å…¥,Operation
åˆ é™¤,Operation
æŸ¥æ‰¾,Operation
éå†,Operation
åˆå§‹åŒ–,Operation
æ‰©å®¹,Operation
ç¼©å®¹,Operation
å¤åˆ¶,Operation
åˆå¹¶,Operation
ç§»åŠ¨,Operation
é”€æ¯,Operation
è·¯å¾„å‹ç¼©,Operation
æ—‹è½¬,Operation
é¡ºåºè®¿é—®,Operation
éšæœºè®¿é—®,Operation
æŒ‰ç§©åˆå¹¶,Operation
å†…å­˜åˆ†é…,Operation
åƒåœ¾å›æ”¶,Operation
å¼•ç”¨è®¡æ•°,Operation
å¿«é€Ÿæ’åº,Algorithm
æ·±åº¦ä¼˜å…ˆæœç´¢,Algorithm
å¹¿åº¦ä¼˜å…ˆæœç´¢,Algorithm
Dijkstraç®—æ³•,Algorithm
KMPç®—æ³•,Algorithm
å†’æ³¡æ’åº,Algorithm
é€‰æ‹©æ’åº,Algorithm
æ’å…¥æ’åº,Algorithm
å½’å¹¶æ’åº,Algorithm
å †æ’åº,Algorithm
æ‹“æ‰‘æ’åº,Algorithm
æœ€å°ç”Ÿæˆæ ‘,Algorithm
ç›´æ¥æ’å…¥æ’åº,Algorithm
å¸Œå°”æ’åº,Algorithm
åŸºæ•°æ’åº,Algorithm
å…‹é²æ–¯å¡å°”ç®—æ³•,Algorithm
æ™®é‡Œå§†ç®—æ³•,Algorithm
è¿ªæ°æ–¯ç‰¹æ‹‰ç®—æ³•,Algorithm
å¼—æ´›ä¼Šå¾·ç®—æ³•,Algorithm
åˆ†æ²»,Algorithm
è´ªå¿ƒç­–ç•¥,Algorithm
åŠ¨æ€è§„åˆ’,Algorithm
å›æº¯æ³•,Algorithm
ç©·ä¸¾æ³•,Algorithm
æ’å€¼æŸ¥æ‰¾,Algorithm
æŠ˜åŠæŸ¥æ‰¾,Algorithm
è®¡æ•°æ’åº,Algorithm
å•æºæœ€çŸ­è·¯å¾„,Algorithm
å¤–éƒ¨æ’åº,Algorithm
æ¡¶æ’åº,Algorithm
å“ˆå¸ŒæŸ¥æ‰¾,Algorithm
åˆ†æ”¯é™ç•Œ,Algorithm
åˆ†å—æŸ¥æ‰¾,Algorithm
è®°å¿†åŒ–æœç´¢,Algorithm
Bellman-Fordç®—æ³•,Algorithm
äºŒè·¯å½’å¹¶,Algorithm
çº¿æ€§æŸ¥æ‰¾,Algorithm
å¤šè·¯å½’å¹¶,Algorithm
çŠ¶æ€è½¬ç§»,Algorithm
O(1),Complexity
O(log n),Complexity
O(n),Complexity
O(n log n),Complexity
O(nÂ²),Complexity
æœ€åæƒ…å†µ,Complexity
å¹³å‡æƒ…å†µ,Complexity
æœ€å¥½æƒ…å†µ,Complexity
å¹³å‡æŸ¥æ‰¾é•¿åº¦,Complexity
æ¸è¿‘å¤æ‚åº¦,Complexity
æ‘Šè¿˜åˆ†æ,Complexity
ä¼šè®¡æ–¹æ³•,Complexity
èšåˆåˆ†æ,Complexity
åŠ¿èƒ½æ–¹æ³•,Complexity
Î˜è®°å·,Complexity
Î©è®°å·,Complexity
å¤§Oè®°å·,Complexity
æ—¶é—´å¤æ‚åº¦,Complexity
ç©ºé—´å¤æ‚åº¦,Complexity
è¡¨è¾¾å¼æ±‚å€¼,ApplicationScenario
ä»»åŠ¡è°ƒåº¦,ApplicationScenario
è¿·å®«æ±‚è§£,ApplicationScenario
æœ€çŸ­è·¯å¾„,ApplicationScenario
æ‹¬å·åŒ¹é…,ApplicationScenario
LIFO,PrincipleOrProperty
FIFO,PrincipleOrProperty
ç¨³å®šæ€§,PrincipleOrProperty
åŸåœ°æ’åº,PrincipleOrProperty
æœ‰ç©·æ€§,PrincipleOrProperty
ç¡®å®šæ€§,PrincipleOrProperty
å¯è¡Œæ€§,PrincipleOrProperty
æœ€ä¼˜å­ç»“æ„,PrincipleOrProperty
è´ªå¿ƒé€‰æ‹©æ€§è´¨,PrincipleOrProperty
å±€éƒ¨æœ€ä¼˜,PrincipleOrProperty
å…¨å±€æœ€ä¼˜,PrincipleOrProperty
é‡å å­é—®é¢˜,PrincipleOrProperty
é¡ºåºå­˜å‚¨,PrincipleOrProperty
é“¾å¼å­˜å‚¨,PrincipleOrProperty
æ— åºåºåˆ—,PrincipleOrProperty
æœ‰åºåºåˆ—,PrincipleOrProperty
çº¿æ€§ç»“æ„,PrincipleOrProperty
éçº¿æ€§ç»“æ„,PrincipleOrProperty
        """
        
        # è§£æå®ä½“åˆ—è¡¨
        entities = []
        for line in entities_str.strip().split('\n'):
            if ',' in line:
                name, entity_type = line.strip().split(',', 1)
                entities.append({"name": name, "type": entity_type})
        return entities

    def generate_prompt(self, entity):
        """ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆå¤§æ¨¡å‹æç¤ºè¯ï¼ˆä¼˜åŒ–åçš„æç¤ºè¯ï¼‰"""
        # è·å–è¯¥ç±»å‹éœ€è¦çš„ä¼˜åŒ–å±æ€§
        attrs = self.optimized_attrs.get(entity["type"], [])
        
        # åˆ›å»ºå±æ€§è¦æ±‚å­—ç¬¦ä¸²
        attrs_str = ", ".join(attrs)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªè®¡ç®—æœºç§‘å­¦ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹æ•°æ®ç»“æ„çŸ¥è¯†å›¾è°±å®ä½“ç”Ÿæˆè¯¦ç»†å±æ€§ã€‚å¿…é¡»ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼ŒåªåŒ…å«ä»¥ä¸‹å±æ€§ï¼š
{attrs_str}

å®ä½“ç±»å‹ï¼š{entity["type"]}
å®ä½“åç§°ï¼š{entity["name"]}

è¦æ±‚ï¼š
1. æ‰€æœ‰å±æ€§å¿…é¡»å¡«å†™ï¼ˆæ— åˆ™å¡«"æœªå®šä¹‰"ï¼‰
2. æ—¶é—´å¤æ‚åº¦å±æ€§å¿…é¡»ç”¨å­—å…¸æ ¼å¼ï¼ˆå¦‚ï¼š{{"å…¥æ ˆ": "O(1)"}})
3. ä»…è¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–ä»»ä½•æ–‡æœ¬
4. ç¡®ä¿å±æ€§å€¼åŸºäºæ ‡å‡†è®¡ç®—æœºç§‘å­¦çŸ¥è¯†ï¼ˆå‚è€ƒã€Šç®—æ³•å¯¼è®ºã€‹ï¼‰
5. ä¸ºOperationç±»å‹æ·»åŠ typical_usageï¼ˆå…¸å‹ä½¿ç”¨åœºæ™¯ï¼‰
6. ä¸ºComplexityç±»å‹æ·»åŠ best_case/average_case/worst_caseï¼ˆæœ€å¥½/å¹³å‡/æœ€åæƒ…å†µï¼‰
"""
        return prompt

    def get_cache_key(self, prompt):
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(prompt.encode('utf-8')).hexdigest()
    
    def load_cache(self):
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                print(f"âœ… åŠ è½½ç¼“å­˜: {len(self.cache)} æ¡è®°å½•")
                # åˆå§‹åŒ–ç¼“å­˜å¤§å°è®°å½•
                self._last_cache_size = len(self.cache)
            else:
                self.cache = {}
                self._last_cache_size = 0
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            self.cache = {}
            self._last_cache_size = 0
    
    def save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œé¿å…é¢‘ç¹IOï¼‰"""
        try:
            with self.cache_lock:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ç¼“å­˜å†…å®¹éœ€è¦ä¿å­˜
                if hasattr(self, '_last_cache_size') and len(self.cache) == self._last_cache_size:
                    return  # æ²¡æœ‰æ–°å†…å®¹ï¼Œè·³è¿‡ä¿å­˜
                
                with open(self.cache_file, 'w', encoding='utf-8') as f:
                    json.dump(self.cache, f, ensure_ascii=False, indent=2)
                
                # è®°å½•å½“å‰ç¼“å­˜å¤§å°
                self._last_cache_size = len(self.cache)
                
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def call_model_api(self, prompt):
        """è°ƒç”¨æ¨¡å‹APIï¼ˆå¸¦ç¼“å­˜å’Œé‡è¯•æœºåˆ¶ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self.get_cache_key(prompt)
        with self.cache_lock:
            if cache_key in self.cache:
                print("  ğŸ“‹ ä½¿ç”¨ç¼“å­˜å“åº”")
                return self.cache[cache_key]
        
        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        messages = [{"role": "user", "content": prompt}]
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.retry_attempts):
            try:
                # è°ƒç”¨API
                response = self.client.chat.completions.create(
                    model=self.model_id,
                    messages=messages,
                    max_tokens=2048,  # ä¼˜åŒ–ï¼šå‡å°‘tokenæ•°é‡
                    temperature=0.5,  # ä¼˜åŒ–ï¼šé™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
                    top_p=0.9,       # ä¼˜åŒ–ï¼šæé«˜å“åº”è´¨é‡
                    stream=False,     # ä¼˜åŒ–ï¼šéæµå¼å“åº”æ›´å¿«
                    timeout=self.api_timeout  # è®¾ç½®è¶…æ—¶
                )
                
                # æå–å“åº”å†…å®¹
                if response.choices and response.choices[0].message:
                    content = response.choices[0].message.content
                    
                    # ç¼“å­˜å“åº”å¹¶ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶
                    with self.cache_lock:
                        self.cache[cache_key] = content
                    
                    # ç«‹å³ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶
                    self.save_cache()
                    print("  ğŸ’¾ ç¼“å­˜å·²ä¿å­˜")
                    
                    return content
                else:
                    print(f"  âš ï¸ APIå“åº”æ ¼å¼å¼‚å¸¸")
                    return None
                    
            except Exception as e:
                error_msg = str(e)
                print(f"  âŒ APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.retry_attempts}): {error_msg}")
                
                # æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é‡è¯•ç­–ç•¥
                if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
                    # è¶…æ—¶é”™è¯¯ï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                    wait_time = self.retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                    print(f"  â³ æ£€æµ‹åˆ°è¶…æ—¶é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                elif "rate limit" in error_msg.lower() or "429" in error_msg:
                    # é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
                    wait_time = self.retry_delay * (3 ** attempt)
                    print(f"  â³ æ£€æµ‹åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œæ­£å¸¸ç­‰å¾…
                    wait_time = self.retry_delay * (attempt + 1)
                    if attempt < self.retry_attempts - 1:
                        time.sleep(wait_time)
                
                if attempt >= self.retry_attempts - 1:
                    print(f"  âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè·³è¿‡æ­¤å®ä½“")
                    return None

    def parse_model_response(self, response):
        """è§£æå¤§æ¨¡å‹è¿”å›çš„JSONå­—ç¬¦ä¸²ï¼ˆä¼˜åŒ–è§£æï¼‰"""
        # å°è¯•æå–JSONï¼ˆå¤„ç†å¯èƒ½çš„é¢å¤–æ–‡æœ¬ï¼‰
        json_match = re.search(r'\{[\s\S]*\}', response)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except:
                pass
        
        # å°è¯•ç›´æ¥è§£æï¼ˆå¦‚æœè¿”å›çš„æ˜¯çº¯JSONï¼‰
        try:
            return json.loads(response)
        except:
            return {}

    def process_single_entity(self, entity_info):
        """å¤„ç†å•ä¸ªå®ä½“ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
        i, entity, total = entity_info
        print(f"å¤„ç†å®ä½“ {i}/{total}: {entity['name']} ({entity['type']})")
        
        # ç”Ÿæˆæç¤ºè¯
        prompt = self.generate_prompt(entity)
        
        # è°ƒç”¨API
        response = self.call_model_api(prompt)
        
        # è§£æå“åº”
        if not response:
            print(f"  âš ï¸ æœªæ”¶åˆ°æœ‰æ•ˆå“åº”ï¼Œè·³è¿‡å®ä½“: {entity['name']}")
            parsed = {}
        else:
            parsed = self.parse_model_response(response)
        
        # åˆå¹¶åŸå§‹å®ä½“å’Œç”Ÿæˆå±æ€§
        full_entity = {
            "type": entity["type"],
            "name": entity["name"],
            **parsed  # æ·»åŠ ç”Ÿæˆçš„å±æ€§
        }
        
        # ç¡®ä¿æ‰€æœ‰ä¼˜åŒ–å±æ€§éƒ½å­˜åœ¨ï¼ˆé¿å…ç¼ºå¤±ï¼‰
        for attr in self.optimized_attrs.get(entity["type"], []):
            if attr not in full_entity:
                full_entity[attr] = "æœªå®šä¹‰"
        
        return full_entity

    def generate_attributes(self):
        """ä¸ºä¸»å®ä½“ç”Ÿæˆæ‰€æœ‰å±æ€§ï¼ˆå¹¶å‘ä¼˜åŒ–ç‰ˆï¼‰"""
        results = []
        total = len(self.entities)
        
        # å‡†å¤‡å®ä½“ä¿¡æ¯
        entity_infos = [(i+1, entity, total) for i, entity in enumerate(self.entities)]
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†ï¼Œæ·»åŠ æ‰¹æ¬¡å¤„ç†ä»¥å‡å°‘APIå‹åŠ›
        batch_size = 5  # æ¯æ‰¹å¤„ç†5ä¸ªå®ä½“
        
        for i in range(0, len(entity_infos), batch_size):
            batch = entity_infos[i:i+batch_size]
            print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(total + batch_size - 1)//batch_size}")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤å½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡
                future_to_entity = {
                    executor.submit(self.process_single_entity, entity_info): entity_info 
                    for entity_info in batch
                }
                
                # æ”¶é›†å½“å‰æ‰¹æ¬¡çš„ç»“æœ
                batch_results = []
                for future in concurrent.futures.as_completed(future_to_entity):
                    try:
                        result = future.result()
                        batch_results.append(result)
                        
                    except Exception as e:
                        entity_info = future_to_entity[future]
                        print(f"  âŒ å¤„ç†å®ä½“å¤±è´¥: {entity_info[1]['name']} - {e}")
                
                results.extend(batch_results)
                
                # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼Œé¿å…APIå‹åŠ›è¿‡å¤§
                if i + batch_size < len(entity_infos):
                    print(f"  ğŸ’¤ æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯1ç§’...")
                    time.sleep(1)
            
            # å®šæœŸä¿å­˜ç¼“å­˜ï¼ˆç§»é™¤ï¼Œå› ä¸ºç°åœ¨æ¯ä¸ªå®ä½“å¤„ç†å®Œéƒ½ä¼šä¿å­˜ï¼‰
            # if len(results) % 10 == 0:
            #     self.save_cache()
            #     print(f"  ğŸ’¾ å·²å¤„ç† {len(results)}/{total} ä¸ªå®ä½“ï¼Œç¼“å­˜å·²ä¿å­˜")
        
        # æœ€ç»ˆä¿å­˜ç¼“å­˜
        self.save_cache()
        print(f"âœ… å¤„ç†å®Œæˆï¼Œå…± {len(results)} ä¸ªå®ä½“")
        
        return results

    def save_to_json(self, data):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆä¼˜åŒ–æ ¼å¼ï¼‰"""
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… å·²ä¿å­˜åˆ°: {self.output_file}")
        print(f"æ€»å®ä½“æ•°: {len(data)} | ç”Ÿæˆæ—¶é—´: {time.time() - self.start_time:.2f}ç§’")

    def validate_kg(self, data):
        """éªŒè¯ç”Ÿæˆçš„JSONæ˜¯å¦ç¬¦åˆçŸ¥è¯†å›¾è°±è§„èŒƒ"""
        print("\nğŸ” æ­£åœ¨éªŒè¯çŸ¥è¯†å›¾è°±æ•°æ®è§„èŒƒ...")
        valid_types = set(self.optimized_attrs.keys())
        
        for i, entity in enumerate(data, 1):
            # éªŒè¯ç±»å‹
            if entity["type"] not in valid_types:
                raise ValueError(f"å®ä½“{entity['name']}ç±»å‹æ— æ•ˆ: {entity['type']}")
            
            # éªŒè¯å¿…éœ€å±æ€§
            required_attrs = self.optimized_attrs.get(entity["type"], [])
            missing = [attr for attr in required_attrs if attr not in entity]
            if missing:
                print(f"  âš ï¸ å®ä½“ {entity['name']} ç¼ºå°‘å±æ€§: {missing}")
        
        print("âœ… çŸ¥è¯†å›¾è°±æ•°æ®éªŒè¯é€šè¿‡")
        return True

    def run(self):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        try:
            # 1. ç”Ÿæˆå±æ€§
            generated_data = self.generate_attributes()
            
            # 2. ä¿å­˜ç»“æœ
            self.save_to_json(generated_data)
            
            # 3. éªŒè¯æ•°æ®
            self.validate_kg(generated_data)
            
            print("\nğŸ‰ çŸ¥è¯†å›¾è°±å±æ€§ç”Ÿæˆå®Œæˆï¼")
            print(f"âœ… ç”Ÿæˆæ–‡ä»¶: {self.output_file}")
            print("âœ… ç”Ÿæˆæ—¶é—´: {:.2f}ç§’".format(time.time() - self.start_time))
            
        except Exception as e:
            print(f"\nğŸš¨ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {str(e)}")
        
            sys.exit(1)

if __name__ == "__main__":
    try:
        generator = KGAttributeGenerator()
        generator.run()
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        sys.exit(1)