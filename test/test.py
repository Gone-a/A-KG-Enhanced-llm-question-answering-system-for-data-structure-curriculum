#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹æ¯”å®éªŒ
å¯¹æ¯”æœ‰çŸ¥è¯†å›¾è°±å¢å¼ºå’Œçº¯å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°æ®ç»“æ„ç®—æ³•é¢˜ç›®ä¸Šçš„è¡¨ç°
"""

import os
import sys
import time
import re
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from typing import List, Dict, Any, Tuple
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.config_manager import get_config_manager
from modules.intent_recognition import IntentRecognizer
from modules.knowledge_graph_query import KnowledgeGraphQuery
from modules.backend_api import APIHandler
from modules.doubao_llm import DoubaoLLM

# å¯¼å…¥çŸ¥è¯†åº“
try:
    from intent_recognition.knowledge_base import KNOWLEDGE_BASE
except ImportError:
    KNOWLEDGE_BASE = {"entities": {}, "relations": {}}

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class ExperimentRunner:
    """å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self):
        self.config = get_config_manager()
        self.questions = []
        self.answers = []
        self.results = {
            'kg_enhanced': [],  # çŸ¥è¯†å›¾è°±å¢å¼ºç»“æœ
            'pure_llm': [],     # çº¯LLMç»“æœ
            'performance': {
                'kg_enhanced': [],  # å“åº”æ—¶é—´
                'pure_llm': []
            }
        }
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        
    def _initialize_components(self):
        """åˆå§‹åŒ–å®éªŒç»„ä»¶"""
        logging.info("åˆå§‹åŒ–å®éªŒç»„ä»¶...")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            api_config = self.config.get_api_config()
            llm_config = self.config.get_llm_config()
            self.llm_client = DoubaoLLM(
                user_api_key=api_config.get('ark_api_key'),
                user_model_id=api_config.get('doubao_model_id'),
                base_url=api_config.get('base_url')
            )
            self.llm_client.set_parameters(
                max_tokens=llm_config['max_tokens'],
                temperature=llm_config['temperature']
            )
        except Exception as e:
            logging.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # å°è¯•åˆå§‹åŒ–çŸ¥è¯†å›¾è°±ç›¸å…³ç»„ä»¶
        self.kg_available = False
        try:
            # åˆå§‹åŒ–æ„å›¾è¯†åˆ«å™¨
            model_path = self.config.get('model.nlu_model_path')
            self.intent_recognizer = IntentRecognizer(model_path, KNOWLEDGE_BASE)
            
            # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æŸ¥è¯¢å™¨
            db_config = self.config.get_database_config()
            self.kg_query = KnowledgeGraphQuery(
                db_config['uri'],
                db_config['user_name'], 
                db_config['password']
            )
            
            # åˆå§‹åŒ–APIå¤„ç†å™¨ï¼ˆç”¨äºçŸ¥è¯†å›¾è°±å¢å¼ºï¼‰
            self.api_handler = APIHandler(self.intent_recognizer, self.kg_query, self.llm_client)
            self.kg_available = True
            logging.info("çŸ¥è¯†å›¾è°±ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.warning(f"çŸ¥è¯†å›¾è°±ç»„ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
            self.kg_available = False
        
        logging.info("ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def load_data(self):
        """åŠ è½½é¢˜ç›®å’Œç­”æ¡ˆæ•°æ®"""
        logging.info("åŠ è½½é¢˜ç›®å’Œç­”æ¡ˆæ•°æ®...")
        
        # è¯»å–é¢˜ç›®æ–‡ä»¶
        question_file = os.path.join(os.path.dirname(__file__), 'data', 'ques.txt')
        with open(question_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        # æŒ‰è¡Œåˆ†å‰²å†…å®¹
        lines = content.split('\n')
        
        current_question = None
        current_options = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯é€‰é¡¹
            if re.match(r'^[A-D]\.\s', line):
                current_options.append(line)
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç­”æ¡ˆ
            elif line.startswith('ç­”æ¡ˆï¼š'):
                answer_match = re.search(r'ç­”æ¡ˆï¼š([A-D])', line)
                if answer_match and current_question and len(current_options) == 4:
                    answer = answer_match.group(1)
                    
                    question = {
                        'text': current_question,
                        'options': current_options
                    }
                    self.questions.append(question)
                    self.answers.append(answer)
                    
                    # é‡ç½®å½“å‰é¢˜ç›®çŠ¶æ€
                    current_question = None
                    current_options = []
            # å¦‚æœä¸æ˜¯é€‰é¡¹ä¹Ÿä¸æ˜¯ç­”æ¡ˆï¼Œä¸”å½“å‰æ²¡æœ‰é¢˜ç›®ï¼Œåˆ™ä½œä¸ºæ–°é¢˜ç›®
            elif not current_question and not re.match(r'^[A-D]\.\s', line) and not line.startswith('ç­”æ¡ˆï¼š'):
                current_question = line
        
        logging.info(f"åŠ è½½å®Œæˆ: {len(self.questions)}é“é¢˜ç›®, {len(self.answers)}ä¸ªç­”æ¡ˆ")
        
        # ç¡®ä¿é¢˜ç›®å’Œç­”æ¡ˆæ•°é‡åŒ¹é…
        min_count = min(len(self.questions), len(self.answers))
        self.questions = self.questions[:min_count]
        self.answers = self.answers[:min_count]
        
        logging.info(f"å®é™…ä½¿ç”¨: {len(self.questions)}é“é¢˜ç›®")
    
    def kg_enhanced_answer(self, question: Dict[str, Any]) -> Tuple[str, float]:
        """ä½¿ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºçš„é—®ç­”"""
        start_time = time.time()
        
        try:
            # æ„å»ºå®Œæ•´çš„é—®é¢˜æ–‡æœ¬
            full_question = question['text'] + '\n' + '\n'.join(question['options'])
            
            
            # ä½¿ç”¨APIå¤„ç†å™¨è¿›è¡ŒæŸ¥è¯¢ï¼ˆåŒ…å«çŸ¥è¯†å›¾è°±å¢å¼ºï¼‰
            result = self.api_handler.process_query(full_question)
            
            # æå–ç­”æ¡ˆ
            if result.get('success') and 'message' in result:
                response_text = result['message']
            else:
                response_text = "æ— æ³•è·å–ç­”æ¡ˆ"
           
            
            # ä»å“åº”ä¸­æå–é€‰é¡¹ç­”æ¡ˆ
            answer = self._extract_answer_from_response(response_text)
            
        except Exception as e:
            logging.error(f"çŸ¥è¯†å›¾è°±å¢å¼ºé—®ç­”å¤±è´¥: {e}")
            answer = "ERROR"
        
        response_time = time.time() - start_time
        return answer, response_time
    
    def pure_llm_answer(self, question: Dict[str, Any]) -> Tuple[str, float]:
        """ä½¿ç”¨çº¯å¤§è¯­è¨€æ¨¡å‹é—®ç­”"""
        start_time = time.time()
        
        try:
            # æ„å»ºå®Œæ•´çš„é—®é¢˜æ–‡æœ¬
            full_question = question['text'] + '\n' + '\n'.join(question['options'])
            
            # æ·»åŠ æ˜ç¡®çš„æŒ‡ä»¤
            prompt = f"""è¯·å›ç­”ä»¥ä¸‹æ•°æ®ç»“æ„ä¸ç®—æ³•é€‰æ‹©é¢˜ï¼Œåªéœ€è¦å›ç­”é€‰é¡¹å­—æ¯ï¼ˆAã€Bã€Cæˆ–Dï¼‰ï¼š

{full_question}

è¯·ç›´æ¥å›ç­”é€‰é¡¹å­—æ¯ï¼š"""
            
            # ç›´æ¥è°ƒç”¨LLM
            response = self.llm_client.generate_response(prompt)
            response_text = response.content
            
            # ä»å“åº”ä¸­æå–é€‰é¡¹ç­”æ¡ˆ
            answer = self._extract_answer_from_response(response_text)
            
        except Exception as e:
            logging.error(f"çº¯LLMé—®ç­”å¤±è´¥: {e}")
            answer = "ERROR"
        
        response_time = time.time() - start_time
        return answer, response_time
    
    def _extract_answer_from_response(self, response_text: str) -> str:
        """ä»å“åº”æ–‡æœ¬ä¸­æå–ç­”æ¡ˆé€‰é¡¹"""
        # æŸ¥æ‰¾æ˜ç¡®çš„é€‰é¡¹ç­”æ¡ˆ
        patterns = [
            r'ç­”æ¡ˆ[æ˜¯ä¸º]?\s*[ï¼š:]\s*([A-D])',
            r'é€‰æ‹©\s*([A-D])',
            r'æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸º]?\s*([A-D])',
            r'^([A-D])[ï¼‰)]',
            r'([A-D])[ï¼‰)]\s*æ˜¯?æ­£ç¡®',
            r'é€‰é¡¹\s*([A-D])',
            r'\b([A-D])\b'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response_text, re.IGNORECASE | re.MULTILINE)
            if match:
                return match.group(1).upper()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®ç­”æ¡ˆï¼Œè¿”å›ç¬¬ä¸€ä¸ªå‡ºç°çš„é€‰é¡¹å­—æ¯
        for char in ['A', 'B', 'C', 'D']:
            if char in response_text.upper():
                return char
        
        return "UNKNOWN"
    
    def run_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        logging.info("å¼€å§‹è¿è¡Œå¯¹æ¯”å®éªŒ...")
        
        total_questions = len(self.questions)
        
        for i, question in enumerate(self.questions):
            logging.info(f"å¤„ç†ç¬¬ {i+1}/{total_questions} é¢˜")
            
            # çŸ¥è¯†å›¾è°±å¢å¼ºé—®ç­”
            kg_answer, kg_time = self.kg_enhanced_answer(question)
            self.results['kg_enhanced'].append(kg_answer)
            self.results['performance']['kg_enhanced'].append(kg_time)
            
            # çº¯LLMé—®ç­”
            llm_answer, llm_time = self.pure_llm_answer(question)
            self.results['pure_llm'].append(llm_answer)
            self.results['performance']['pure_llm'].append(llm_time)
            
            logging.info(f"é¢˜ç›® {i+1}: KGå¢å¼º={kg_answer}, çº¯LLM={llm_answer}, æ­£ç¡®ç­”æ¡ˆ={self.answers[i]}")
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(0.5)
        
        logging.info("å®éªŒå®Œæˆ")
    
    def calculate_accuracy(self):
        """è®¡ç®—å‡†ç¡®ç‡"""
        if len(self.answers) == 0:
            logging.warning("æ²¡æœ‰é¢˜ç›®æ•°æ®ï¼Œæ— æ³•è®¡ç®—å‡†ç¡®ç‡")
            return {
                'kg_enhanced': {
                    'correct': 0,
                    'total': 0,
                    'accuracy': 0.0
                },
                'pure_llm': {
                    'correct': 0,
                    'total': 0,
                    'accuracy': 0.0
                }
            }
        
        kg_correct = sum(1 for i, answer in enumerate(self.results['kg_enhanced']) 
                        if answer == self.answers[i])
        llm_correct = sum(1 for i, answer in enumerate(self.results['pure_llm']) 
                         if answer == self.answers[i])
        
        total = len(self.answers)
        kg_accuracy = kg_correct / total * 100
        llm_accuracy = llm_correct / total * 100
        
        return {
            'kg_enhanced': {
                'correct': kg_correct,
                'total': total,
                'accuracy': kg_accuracy
            },
            'pure_llm': {
                'correct': llm_correct,
                'total': total,
                'accuracy': llm_accuracy
            }
        }
    
    def analyze_performance(self):
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        kg_times = self.results['performance']['kg_enhanced']
        llm_times = self.results['performance']['pure_llm']
        
        return {
            'kg_enhanced': {
                'avg_time': sum(kg_times) / len(kg_times),
                'min_time': min(kg_times),
                'max_time': max(kg_times),
                'total_time': sum(kg_times)
            },
            'pure_llm': {
                'avg_time': sum(llm_times) / len(llm_times),
                'min_time': min(llm_times),
                'max_time': max(llm_times),
                'total_time': sum(llm_times)
            }
        }
    
    def generate_charts(self):
        """ç”Ÿæˆå¯¹æ¯”åˆ†æå›¾è¡¨"""
        logging.info("ç”Ÿæˆå¯¹æ¯”åˆ†æå›¾è¡¨...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(self.answers) == 0:
            logging.warning("æ²¡æœ‰é¢˜ç›®æ•°æ®ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
            return self.calculate_accuracy(), self.analyze_performance()
        
        # è®¡ç®—å‡†ç¡®ç‡å’Œæ€§èƒ½æŒ‡æ ‡
        accuracy_stats = self.calculate_accuracy()
        performance_stats = self.analyze_performance()
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('çŸ¥è¯†å›¾è°±å¢å¼º vs çº¯å¤§è¯­è¨€æ¨¡å‹å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
        ax1 = axes[0, 0]
        methods = ['çŸ¥è¯†å›¾è°±å¢å¼º', 'çº¯å¤§è¯­è¨€æ¨¡å‹']
        accuracies = [accuracy_stats['kg_enhanced']['accuracy'], 
                     accuracy_stats['pure_llm']['accuracy']]
        colors = ['#2E86AB', '#A23B72']
        
        bars = ax1.bar(methods, accuracies, color=colors, alpha=0.8)
        ax1.set_title('å‡†ç¡®ç‡å¯¹æ¯”', fontweight='bold')
        ax1.set_ylabel('å‡†ç¡®ç‡ (%)')
        ax1.set_ylim(0, 100)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # 2. å“åº”æ—¶é—´å¯¹æ¯”ç®±çº¿å›¾
        ax2 = axes[0, 1]
        time_data = [self.results['performance']['kg_enhanced'],
                    self.results['performance']['pure_llm']]
        
        if len(time_data[0]) > 0 and len(time_data[1]) > 0:
            box_plot = ax2.boxplot(time_data, labels=methods, patch_artist=True)
            box_plot['boxes'][0].set_facecolor(colors[0])
            box_plot['boxes'][1].set_facecolor(colors[1])
        else:
            ax2.text(0.5, 0.5, 'æ— æ€§èƒ½æ•°æ®', ha='center', va='center', transform=ax2.transAxes)
        
        ax2.set_title('å“åº”æ—¶é—´åˆ†å¸ƒ', fontweight='bold')
        ax2.set_ylabel('å“åº”æ—¶é—´ (ç§’)')
        
        # 3. é€é¢˜å‡†ç¡®æ€§å¯¹æ¯”
        ax3 = axes[1, 0]
        if len(self.answers) > 0:
            question_nums = list(range(1, len(self.answers) + 1))
            kg_correct_list = [1 if self.results['kg_enhanced'][i] == self.answers[i] else 0 
                              for i in range(len(self.answers))]
            llm_correct_list = [1 if self.results['pure_llm'][i] == self.answers[i] else 0 
                               for i in range(len(self.answers))]
            
            # è®¡ç®—æ»‘åŠ¨å¹³å‡å‡†ç¡®ç‡
            window_size = min(10, len(self.answers))
            kg_rolling = pd.Series(kg_correct_list).rolling(window=window_size, min_periods=1).mean()
            llm_rolling = pd.Series(llm_correct_list).rolling(window=window_size, min_periods=1).mean()
            
            ax3.plot(question_nums, kg_rolling, label='çŸ¥è¯†å›¾è°±å¢å¼º', color=colors[0], linewidth=2)
            ax3.plot(question_nums, llm_rolling, label='çº¯å¤§è¯­è¨€æ¨¡å‹', color=colors[1], linewidth=2)
            ax3.set_title(f'æ»‘åŠ¨å¹³å‡å‡†ç¡®ç‡è¶‹åŠ¿ (çª—å£å¤§å°: {window_size})', fontweight='bold')
            ax3.set_xlabel('é¢˜ç›®ç¼–å·')
            ax3.set_ylabel('å‡†ç¡®ç‡')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æ— é¢˜ç›®æ•°æ®', ha='center', va='center', transform=ax3.transAxes)
        
        # 4. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”é›·è¾¾å›¾
        ax4 = axes[1, 1]
        
        if len(self.answers) > 0 and len(self.results['performance']['kg_enhanced']) > 0:
            # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
            categories = ['å‡†ç¡®ç‡', 'å¹³å‡å“åº”æ—¶é—´\n(å½’ä¸€åŒ–)', 'ç¨³å®šæ€§\n(1/æ ‡å‡†å·®)']
            
            # å½’ä¸€åŒ–æ•°æ®
            kg_acc_norm = accuracy_stats['kg_enhanced']['accuracy'] / 100
            llm_acc_norm = accuracy_stats['pure_llm']['accuracy'] / 100
            
            max_time = max(performance_stats['kg_enhanced']['avg_time'], 
                          performance_stats['pure_llm']['avg_time'])
            kg_time_norm = 1 - (performance_stats['kg_enhanced']['avg_time'] / max_time) if max_time > 0 else 0
            llm_time_norm = 1 - (performance_stats['pure_llm']['avg_time'] / max_time) if max_time > 0 else 0
            
            kg_std = pd.Series(self.results['performance']['kg_enhanced']).std()
            llm_std = pd.Series(self.results['performance']['pure_llm']).std()
            max_std = max(kg_std, llm_std)
            kg_stability = 1 - (kg_std / max_std) if max_std > 0 else 1
            llm_stability = 1 - (llm_std / max_std) if max_std > 0 else 1
            
            kg_values = [kg_acc_norm, kg_time_norm, kg_stability]
            llm_values = [llm_acc_norm, llm_time_norm, llm_stability]
            
            # åˆ›å»ºç®€åŒ–çš„å¯¹æ¯”å›¾
            x = range(len(categories))
            width = 0.35
            
            ax4.bar([i - width/2 for i in x], kg_values, width, label='çŸ¥è¯†å›¾è°±å¢å¼º', 
                   color=colors[0], alpha=0.8)
            ax4.bar([i + width/2 for i in x], llm_values, width, label='çº¯å¤§è¯­è¨€æ¨¡å‹', 
                   color=colors[1], alpha=0.8)
            
            ax4.set_title('ç»¼åˆæ€§èƒ½å¯¹æ¯”', fontweight='bold')
            ax4.set_ylabel('å½’ä¸€åŒ–å¾—åˆ†')
            ax4.set_xticks(x)
            ax4.set_xticklabels(categories)
            ax4.legend()
            ax4.set_ylim(0, 1)
        else:
            ax4.text(0.5, 0.5, 'æ— æ€§èƒ½æ•°æ®', ha='center', va='center', transform=ax4.transAxes)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        chart_file = f'/root/KG_inde/test/comparison_analysis_{timestamp}.png'
        plt.savefig(chart_file, dpi=300, bbox_inches='tight')
        logging.info(f"å›¾è¡¨å·²ä¿å­˜: {chart_file}")
        
        plt.show()
        
        return accuracy_stats, performance_stats
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f'/root/KG_inde/test/experiment_results_{timestamp}.json'
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            'timestamp': timestamp,
            'total_questions': len(self.questions),
            'results': self.results,
            'correct_answers': self.answers,
            'accuracy_stats': self.calculate_accuracy(),
            'performance_stats': self.analyze_performance()
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        logging.info(f"å®éªŒç»“æœå·²ä¿å­˜: {results_file}")
        return results_file

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("çŸ¥è¯†å›¾è°±ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå®éªŒè¿è¡Œå™¨
        runner = ExperimentRunner()
        
        # åŠ è½½æ•°æ®
        runner.load_data()
        
        # è¿è¡Œå®éªŒ
        runner.run_experiment()
        
        # ç”Ÿæˆåˆ†æå›¾è¡¨
        accuracy_stats, performance_stats = runner.generate_charts()
        
        # ä¿å­˜ç»“æœ
        results_file = runner.save_results()
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 60)
        print("å®éªŒç»“æœæ€»ç»“")
        print("=" * 60)
        
        print(f"\nğŸ“Š å‡†ç¡®ç‡å¯¹æ¯”:")
        print(f"  çŸ¥è¯†å›¾è°±å¢å¼º: {accuracy_stats['kg_enhanced']['correct']}/{accuracy_stats['kg_enhanced']['total']} "
              f"({accuracy_stats['kg_enhanced']['accuracy']:.1f}%)")
        print(f"  çº¯å¤§è¯­è¨€æ¨¡å‹: {accuracy_stats['pure_llm']['correct']}/{accuracy_stats['pure_llm']['total']} "
              f"({accuracy_stats['pure_llm']['accuracy']:.1f}%)")
        
        print(f"\nâ±ï¸ æ€§èƒ½å¯¹æ¯”:")
        print(f"  çŸ¥è¯†å›¾è°±å¢å¼ºå¹³å‡å“åº”æ—¶é—´: {performance_stats['kg_enhanced']['avg_time']:.2f}ç§’")
        print(f"  çº¯å¤§è¯­è¨€æ¨¡å‹å¹³å‡å“åº”æ—¶é—´: {performance_stats['pure_llm']['avg_time']:.2f}ç§’")
        
        improvement = accuracy_stats['kg_enhanced']['accuracy'] - accuracy_stats['pure_llm']['accuracy']
        print(f"\nğŸ“ˆ å‡†ç¡®ç‡æå‡: {improvement:+.1f}%")
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {results_file}")
        print("=" * 60)
        
    except Exception as e:
        logging.error(f"å®éªŒè¿è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()