#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±ä¼˜åŒ–è„šæœ¬
è§£å†³å…³ç³»è¿‡äºç¹æ‚çš„é—®é¢˜ï¼Œæå‡å›¾è°±è´¨é‡
"""

from py2neo import Graph
import json
import os
from collections import defaultdict, Counter

class GraphOptimizer:
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="123456"):
        """åˆå§‹åŒ–Neo4jè¿æ¥"""
        try:
            password = os.getenv("NEO4J_KEY", password)
            self.graph = Graph(uri, auth=(user, password))
            self.graph.run("RETURN 1")
            print("âœ… Neo4jå›¾æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {e}")
            raise e
    
    def analyze_graph_complexity(self):
        """åˆ†æå›¾çš„å¤æ‚æ€§"""
        print("ğŸ” åˆ†æå›¾è°±å¤æ‚æ€§...")
        
        # ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
        node_count = self.graph.run("MATCH (n) RETURN count(n) as count").data()[0]['count']
        rel_count = self.graph.run("MATCH ()-[r]->() RETURN count(r) as count").data()[0]['count']
        
        # ç»Ÿè®¡å…³ç³»ç±»å‹
        rel_types = self.graph.run("""
            MATCH ()-[r]->()
            RETURN type(r) as relation_type, count(r) as count
            ORDER BY count DESC
        """).data()
        
        # ç»Ÿè®¡åŒå‘å…³ç³»
        bidirectional_query = """
            MATCH (a)-[r1]->(b), (b)-[r2]->(a)
            WHERE type(r1) = type(r2)
            RETURN type(r1) as relation_type, count(DISTINCT a) as bidirectional_pairs
        """
        bidirectional = self.graph.run(bidirectional_query).data()
        
        print(f"ğŸ“Š å›¾è°±ç»Ÿè®¡:")
        print(f"   - èŠ‚ç‚¹æ•°é‡: {node_count}")
        print(f"   - å…³ç³»æ•°é‡: {rel_count}")
        print(f"   - å¹³å‡æ¯ä¸ªèŠ‚ç‚¹çš„å…³ç³»æ•°: {rel_count/node_count:.1f}")
        
        print(f"\nğŸ“Š å…³ç³»ç±»å‹åˆ†å¸ƒ:")
        for rel_type in rel_types:
            print(f"   - {rel_type['relation_type']}: {rel_type['count']} ä¸ª")
        
        print(f"\nğŸ”„ åŒå‘å…³ç³»ç»Ÿè®¡:")
        total_bidirectional = 0
        for bid in bidirectional:
            pairs = bid['bidirectional_pairs']
            total_bidirectional += pairs * 2  # æ¯å¯¹åŒå‘å…³ç³»åŒ…å«2ä¸ªå…³ç³»
            print(f"   - {bid['relation_type']}: {pairs} å¯¹åŒå‘å…³ç³»")
        
        print(f"\nâš ï¸ é—®é¢˜è¯†åˆ«:")
        print(f"   - åŒå‘å…³ç³»å æ¯”: {total_bidirectional/rel_count*100:.1f}%")
        if total_bidirectional/rel_count > 0.3:
            print("   - å»ºè®®: åŒå‘å…³ç³»è¿‡å¤šï¼Œéœ€è¦ä¼˜åŒ–")
        
        return {
            'node_count': node_count,
            'rel_count': rel_count,
            'rel_types': rel_types,
            'bidirectional_count': total_bidirectional
        }
    
    def remove_bidirectional_duplicates(self):
        """ç§»é™¤åŒå‘é‡å¤å…³ç³»ï¼Œåªä¿ç•™ä¸€ä¸ªæ–¹å‘"""
        print("ğŸ§¹ ç§»é™¤åŒå‘é‡å¤å…³ç³»...")
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒå‘å…³ç³»å¯¹
        bidirectional_query = """
            MATCH (a)-[r1]->(b), (b)-[r2]->(a)
            WHERE type(r1) = type(r2) AND id(a) < id(b)
            RETURN a.name as node_a, b.name as node_b, type(r1) as relation_type, 
                   id(r1) as r1_id, id(r2) as r2_id
        """
        
        bidirectional_pairs = self.graph.run(bidirectional_query).data()
        
        removed_count = 0
        for pair in bidirectional_pairs:
            # åˆ é™¤å…¶ä¸­ä¸€ä¸ªå…³ç³»ï¼ˆä¿ç•™idè¾ƒå°çš„ï¼‰
            delete_query = f"MATCH ()-[r]->() WHERE id(r) = {pair['r2_id']} DELETE r"
            self.graph.run(delete_query)
            removed_count += 1
        
        print(f"âœ… ç§»é™¤äº† {removed_count} ä¸ªé‡å¤çš„åŒå‘å…³ç³»")
        return removed_count
    
    def filter_low_quality_relations(self):
        """è¿‡æ»¤ä½è´¨é‡å…³ç³»"""
        print("ğŸ” è¯†åˆ«å¹¶ç§»é™¤ä½è´¨é‡å…³ç³»...")
        
        # å®šä¹‰ä¸€äº›ä¸åˆç†çš„å…³ç³»æ¨¡å¼
        problematic_patterns = [
            # åº”ç”¨åœºæ™¯ä¸åº”è¯¥ç›´æ¥appliesToæ•°æ®ç»“æ„ï¼ˆé€šå¸¸æ˜¯ç®—æ³•appliesToåº”ç”¨åœºæ™¯ï¼‰
            ("ApplicationScenario", "appliesTo", "DataStructure"),
            ("ApplicationScenario", "appliesTo", "Algorithm"),
        ]
        
        removed_count = 0
        for head_type, relation, tail_type in problematic_patterns:
            query = f"""
                MATCH (a)-[r:{relation}]->(b)
                WHERE a.type = '{head_type}' AND b.type = '{tail_type}'
                DELETE r
                RETURN count(r) as deleted_count
            """
            try:
                result = self.graph.run(query).data()
                if result:
                    count = result[0].get('deleted_count', 0)
                    removed_count += count
                    print(f"   - ç§»é™¤ {head_type} --[{relation}]--> {tail_type}: {count} ä¸ª")
            except:
                # å¦‚æœèŠ‚ç‚¹æ²¡æœ‰typeå±æ€§ï¼Œè·³è¿‡
                pass
        
        print(f"âœ… ç§»é™¤äº† {removed_count} ä¸ªä½è´¨é‡å…³ç³»")
        return removed_count
    
    def merge_similar_relations(self):
        """åˆå¹¶ç›¸ä¼¼çš„å…³ç³»ç±»å‹"""
        print("ğŸ”„ åˆå¹¶ç›¸ä¼¼å…³ç³»ç±»å‹...")
        
        # å®šä¹‰å…³ç³»ç±»å‹åˆå¹¶æ˜ å°„
        relation_mapping = {
            'usedIn': 'uses',  # usedIn åˆå¹¶åˆ° uses
            'implementedAs': 'uses',  # implementedAs åˆå¹¶åˆ° uses
            'provides': 'appliesTo',  # provides åˆå¹¶åˆ° appliesTo
        }
        
        merged_count = 0
        for old_rel, new_rel in relation_mapping.items():
            query = f"""
                MATCH (a)-[r:{old_rel}]->(b)
                CREATE (a)-[new_r:{new_rel}]->(b)
                DELETE r
                RETURN count(r) as merged_count
            """
            try:
                result = self.graph.run(query).data()
                if result:
                    count = result[0].get('merged_count', 0)
                    merged_count += count
                    print(f"   - {old_rel} -> {new_rel}: {count} ä¸ªå…³ç³»")
            except Exception as e:
                print(f"   - åˆå¹¶ {old_rel} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… åˆå¹¶äº† {merged_count} ä¸ªå…³ç³»")
        return merged_count
    
    def add_relation_weights(self):
        """ä¸ºå…³ç³»æ·»åŠ æƒé‡å±æ€§"""
        print("âš–ï¸ ä¸ºå…³ç³»æ·»åŠ æƒé‡...")
        
        # åŸºäºå…³ç³»ç±»å‹è®¾ç½®æƒé‡
        relation_weights = {
            'appliesTo': 0.9,      # åº”ç”¨å…³ç³»æƒé‡é«˜
            'uses': 0.8,           # ä½¿ç”¨å…³ç³»æƒé‡è¾ƒé«˜
            'variantOf': 0.7,      # å˜ä½“å…³ç³»æƒé‡ä¸­ç­‰
            'hasComplexity': 0.6,  # å¤æ‚åº¦å…³ç³»æƒé‡è¾ƒä½
        }
        
        updated_count = 0
        for rel_type, weight in relation_weights.items():
            query = f"""
                MATCH ()-[r:{rel_type}]->()
                SET r.weight = {weight}
                RETURN count(r) as updated_count
            """
            try:
                result = self.graph.run(query).data()
                if result:
                    count = result[0].get('updated_count', 0)
                    updated_count += count
                    print(f"   - {rel_type}: {count} ä¸ªå…³ç³»è®¾ç½®æƒé‡ {weight}")
            except Exception as e:
                print(f"   - è®¾ç½® {rel_type} æƒé‡æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… ä¸º {updated_count} ä¸ªå…³ç³»æ·»åŠ äº†æƒé‡")
        return updated_count
    
    def optimize_graph(self):
        """æ‰§è¡Œå®Œæ•´çš„å›¾ä¼˜åŒ–æµç¨‹"""
        print("ğŸš€ å¼€å§‹ä¼˜åŒ–çŸ¥è¯†å›¾è°±...")
        
        # 1. åˆ†æå½“å‰çŠ¶æ€
        initial_stats = self.analyze_graph_complexity()
        
        # 2. ç§»é™¤åŒå‘é‡å¤å…³ç³»
        removed_bidirectional = self.remove_bidirectional_duplicates()
        
        # 3. è¿‡æ»¤ä½è´¨é‡å…³ç³»
        removed_low_quality = self.filter_low_quality_relations()
        
        # 4. åˆå¹¶ç›¸ä¼¼å…³ç³»ç±»å‹
        merged_relations = self.merge_similar_relations()
        
        # 5. æ·»åŠ å…³ç³»æƒé‡
        weighted_relations = self.add_relation_weights()
        
        # 6. åˆ†æä¼˜åŒ–åçŠ¶æ€
        print("\nğŸ“Š ä¼˜åŒ–åç»Ÿè®¡:")
        final_stats = self.analyze_graph_complexity()
        
        # 7. æ€»ç»“ä¼˜åŒ–æ•ˆæœ
        print(f"\nğŸ‰ ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“ˆ ä¼˜åŒ–æ•ˆæœ:")
        print(f"   - å…³ç³»æ•°é‡: {initial_stats['rel_count']} -> {final_stats['rel_count']}")
        print(f"   - å‡å°‘å…³ç³»: {initial_stats['rel_count'] - final_stats['rel_count']} ä¸ª")
        print(f"   - ä¼˜åŒ–æ¯”ä¾‹: {(initial_stats['rel_count'] - final_stats['rel_count'])/initial_stats['rel_count']*100:.1f}%")
        
        return final_stats
    
    def export_optimized_graph(self, output_path="/root/KG_inde/Vue/src/data/graph.json"):
        """å¯¼å‡ºä¼˜åŒ–åçš„å›¾æ•°æ®"""
        print("ğŸ“¤ å¯¼å‡ºä¼˜åŒ–åçš„å›¾æ•°æ®...")
        
        # æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹
        nodes_query = "MATCH (n) RETURN DISTINCT n.name as name ORDER BY n.name"
        
        # æŸ¥è¯¢æ‰€æœ‰å…³ç³»ï¼ˆåŒ…å«æƒé‡ï¼‰
        relationships_query = """
            MATCH (a)-[r]->(b)
            RETURN a.name as source, b.name as target, type(r) as relation,
                   COALESCE(r.weight, 0.5) as weight
            ORDER BY weight DESC, a.name, b.name
        """
        
        try:
            # è·å–æ•°æ®
            nodes_result = self.graph.run(nodes_query).data()
            relationships_result = self.graph.run(relationships_query).data()
            
            # æ„å»ºnodesæ•°ç»„
            nodes = []
            for node in nodes_result:
                if node['name']:
                    nodes.append({
                        "id": node['name'],
                        "name": node['name']
                    })
            
            # æ„å»ºlinksæ•°ç»„
            links = []
            for rel in relationships_result:
                if rel['source'] and rel['target'] and rel['relation']:
                    link = {
                        "source": rel['source'],
                        "target": rel['target'],
                        "relation": rel['relation']
                    }
                    # å¦‚æœæœ‰æƒé‡ï¼Œæ·»åŠ æƒé‡ä¿¡æ¯
                    if rel['weight'] > 0:
                        link['weight'] = rel['weight']
                    links.append(link)
            
            # æ„å»ºå›¾æ•°æ®
            graph_data = {
                "nodes": nodes,
                "links": links
            }
            
            # ä¿å­˜æ–‡ä»¶
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(graph_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ä¼˜åŒ–åçš„å›¾æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            print(f"   - èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
            print(f"   - å…³ç³»æ•°é‡: {len(links)}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ•°æ®æ—¶å‡ºé”™: {e}")
            raise e

def main():
    """ä¸»å‡½æ•°"""
    try:
        optimizer = GraphOptimizer()
        
        # æ‰§è¡Œä¼˜åŒ–
        optimizer.optimize_graph()
        
        # å¯¼å‡ºä¼˜åŒ–åçš„æ•°æ®
        optimizer.export_optimized_graph()
        
        print("ğŸ‰ å›¾è°±ä¼˜åŒ–å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())